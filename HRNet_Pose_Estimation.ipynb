{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HRNet - Pose Estimation.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6Zn_B-TmJbF",
        "colab_type": "text"
      },
      "source": [
        "Downloading the repos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mtb22910l6gq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is my fork of HRNet, this is the same as the official repo, minus some dependencies  \n",
        "!git clone https://github.com/ramarlina/Higher-HRNet-Human-Pose-Estimation.git\n",
        "\n",
        "# adding repo to python's paths since we're not going to install it\n",
        "import sys \n",
        "sys.path.append(\"Higher-HRNet-Human-Pose-Estimation/lib\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uly6Eg7ponjt",
        "colab_type": "text"
      },
      "source": [
        "# Creating a HRNet Pose Estimation model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zRrhW27mI7k",
        "colab_type": "text"
      },
      "source": [
        "Some custom code for parsing the yaml config file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xISKxHxkmPTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json \n",
        "import yaml\n",
        "\n",
        "# Loading the yaml file\n",
        "config_file = \"Higher-HRNet-Human-Pose-Estimation/experiments/coco/higher_hrnet/w32_512_adam_lr1e-3.yaml\"\n",
        "config_json = yaml.load(open(config_file))\n",
        " \n",
        "def walk(node):\n",
        "    obj = {}\n",
        "    for key, item in node.items():\n",
        "        if isinstance(item, dict): \n",
        "            obj[key] = ConfigParser(item)\n",
        "        else:\n",
        "            obj[key] = item\n",
        "    return obj\n",
        "\n",
        "# Custom parser class \n",
        "class ConfigParser():\n",
        "    def __init__(self, cfg_json): \n",
        "        self.__dict__ = walk(cfg_json) \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.__dict__[idx]\n",
        "\n",
        "    def __setitem__(self, key, value):\n",
        "        self.__dict__[key] = value\n",
        "\n",
        "    def __repr__(self):\n",
        "        return json.dumps(list(self.__dict__.keys()))\n",
        "\n",
        "config = ConfigParser(config_json)\n",
        "\n",
        "print(\"Weights: \", config.MODEL.PRETRAINED)\n",
        "print(\"Num Joints: \", config.MODEL.NUM_JOINTS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HyMInt1mT5M",
        "colab_type": "text"
      },
      "source": [
        "Instantiating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2LbGtPlmRDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from models.pose_higher_hrnet import PoseHigherResolutionNet \n",
        "import torch\n",
        "\n",
        "# set this to \"cuda\" to use GPU\n",
        "device = \"cpu\" \n",
        "\n",
        "# creating the model\n",
        "model = PoseHigherResolutionNet(config).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCavyPuRoT8p",
        "colab_type": "text"
      },
      "source": [
        "Loading pre-trained weights from the official Google Drive repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUA5sDuFoZth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# downloading pretrained weights from https://drive.google.com/drive/folders/1zJbBbIHVQmHJp89t5CD1VF5TIzldpHXn\n",
        "!gdown https://drive.google.com/uc?id=1V9Iz0ZYy9m8VeaspfKECDW0NKlGsYmO1\n",
        "\n",
        "# loading weights\n",
        "state_dict = torch.load(\"./pose_higher_hrnet_w32_512.pth\")\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZzwDYICohF5",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GgctOllrEXX",
        "colab_type": "text"
      },
      "source": [
        "Helper functions for loading and preprocessing of an image and for predicting pose using the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnV0hv3ER4Nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from utils.transforms import resize_align_multi_scale \n",
        "from utils.transforms import get_multi_scale_size\n",
        "import cv2\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt \n",
        "\n",
        "transforms = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        )\n",
        "])\n",
        " \n",
        "def load_image(fname, resolution=(512,512)): \n",
        "    image = cv2.imread(fname)  \n",
        "    size = image.shape[:-1]\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
        "\n",
        "    base_size, center, scale = get_multi_scale_size(\n",
        "        image, resolution[0], 1.0, 1.0\n",
        "    )\n",
        "\n",
        "    image_resized, center, scale = resize_align_multi_scale(image, 512, 1., 1.)\n",
        "    image_resized = transforms(image_resized)\n",
        "\n",
        "    image_resized = image_resized.unsqueeze(0)\n",
        "    return image, image_resized\n",
        "\n",
        "def predict(model, X, original_size): \n",
        "    model.eval()\n",
        "    outputs = model(X)\n",
        "\n",
        "    n_joints = outputs[-1].shape[1]\n",
        "\n",
        "    hm = 0\n",
        "    for i, output in enumerate(outputs):\n",
        "        if i < len(outputs):\n",
        "            output = torch.nn.functional.interpolate(\n",
        "                output,\n",
        "                size=(original_size[0], original_size[1]),\n",
        "                mode='bilinear',\n",
        "                align_corners=False\n",
        "            )\n",
        "        hm += output[:, :n_joints].detach().cpu().numpy()\n",
        "\n",
        "    hm /= 2\n",
        "\n",
        "    pts = np.zeros((n_joints, 3))\n",
        "    confidence = np.zeros(n_joints)\n",
        "\n",
        "    for i, joint in enumerate(hm[0]):  \n",
        "        pt = np.unravel_index(np.argmax(joint), joint.shape)\n",
        "        pts[i:, :2] = pt[::-1]   \n",
        "        pts[i:, 2] = joint[pt] \n",
        "        \n",
        "    return pts, confidence\n",
        "\n",
        "def visualize_pose(image, pts):\n",
        "    \"\"\"\n",
        "        Visualizing predicted poses\n",
        "    \"\"\"\n",
        "    skeleton = [ \n",
        "        [15, 13], [13, 11], [16, 14], [14, 12], [11, 12], [5, 11], [6, 12], [5, 6], [5, 7],\n",
        "        [6, 8], [7, 9], [8, 10], [1, 2], [0, 1], [0, 2], [1, 3], [2, 4],  # [3, 5], [4, 6]\n",
        "        [0, 5], [0, 6]\n",
        "    ]\n",
        "\n",
        "    plt.figure(figsize=(10,10)) \n",
        "\n",
        "    for i, joint in enumerate(skeleton):\n",
        "        pt1, pt2 = pts[joint] \n",
        "        image = cv2.line(\n",
        "            image, (int(pt1[0]), int(pt1[1])), (int(pt2[0]), int(pt2[1])),\n",
        "            (0,255,0), 5\n",
        "        )\n",
        "\n",
        "    for pt in pts:\n",
        "        image = cv2.circle(image, (int(pt[0]), int(pt[1])), 10, (255,0,0), -1)\n",
        "\n",
        "    return image \n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBaZKKd-ji4d",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42tDlqC3leJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# downloading some image to test the model on\n",
        "!wget https://storage.needpix.com/rsynced_images/man-1453062_1280.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qo-8MI2DL2oc",
        "colab_type": "text"
      },
      "source": [
        "Predicting body pose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDrJHn60njJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading the image\n",
        "image, X = load_image(\"man-1453062_1280.jpg\")\n",
        "\n",
        "# predicting pose\n",
        "pts, confidence = predict(model, X, image.shape[:-1])\n",
        "\n",
        "# visualizing predictions\n",
        "viz = visualize_pose(image, pts)\n",
        " \n",
        "plt.imshow(viz)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LIxnytQL7ra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}